{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, SMOTENC, SMOTEN \n",
    "from sklearn.utils import resample\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('body_level_classification_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['Body_Level'] = df_p['Body_Level'].map({\n",
    "    'Body Level 1': 1, \n",
    "    'Body Level 2': 2, \n",
    "    'Body Level 3': 3, \n",
    "    'Body Level 4': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_ = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample\n",
    "if resample_:\n",
    "    df_p1 = df_p[df_p['Body_Level'] == 1]\n",
    "    df_p2 = df_p[df_p['Body_Level'] == 2]\n",
    "    df_p3 = df_p[df_p['Body_Level'] == 3]\n",
    "    df_p4 = df_p[df_p['Body_Level'] == 4]\n",
    "\n",
    "    max_class_size = max(len(df_p1), len(df_p2), len(df_p3), len(df_p4))\n",
    "\n",
    "    df_p1 = resample(df_p1, replace=True, n_samples=max_class_size, random_state=0)\n",
    "    df_p2 = resample(df_p2, replace=True, n_samples=max_class_size, random_state=0)\n",
    "    df_p3 = resample(df_p3, replace=True, n_samples=max_class_size, random_state=0)\n",
    "    df_p4 = resample(df_p4, replace=True, n_samples=max_class_size, random_state=0)\n",
    "\n",
    "    df_p = pd.concat([df_p1, df_p2, df_p3, df_p4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder for categorical columns except Body_Level\n",
    "le = LabelEncoder()\n",
    "categorical_columns = [col for col in df_p.columns if df_p[col].dtype == 'object']\n",
    "for col in categorical_columns:\n",
    "    df_p[col] = le.fit_transform(df_p[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "scaler = StandardScaler()\n",
    "df_p.iloc[:, :-1] = scaler.fit_transform(df_p.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_p.iloc[:, :-1], df_p.iloc[:, -1], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# SVM\n",
    "param_grid = {'C': [0.1, 1, 3, 5, 7, 10],\n",
    "                'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "# output the cv result to csv\n",
    "pd.DataFrame(grid.cv_results_).to_csv('svm_grid_search_cv.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1, 'kernel': 'linear'}\n",
      "SVC(C=10, gamma=1, kernel='linear')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      1.00      0.99       132\n",
      "           2       0.98      0.97      0.97       138\n",
      "           3       0.99      0.98      0.98       125\n",
      "           4       1.00      1.00      1.00       149\n",
      "\n",
      "    accuracy                           0.99       544\n",
      "   macro avg       0.99      0.99      0.99       544\n",
      "weighted avg       0.99      0.99      0.99       544\n",
      "\n",
      "[[132   0   0   0]\n",
      " [  3 134   1   0]\n",
      " [  0   3 122   0]\n",
      " [  0   0   0 149]]\n",
      "0.9867951168078025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, grid_predictions))\n",
    "print(confusion_matrix(y_test, grid_predictions))      \n",
    "# print f1 score\n",
    "print(f1_score(y_test, grid_predictions, average='macro'))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "param_grid = {'n_estimators': [10, 50, 100, 200, 500],\n",
    "                'max_features': ['sqrt', 'log2'],\n",
    "                'max_depth' : [4,5,6,7,8],\n",
    "                'criterion' :['gini', 'entropy']}\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, refit=True, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "# output cv results to csv\n",
    "pd.DataFrame(grid.cv_results_).to_csv('random_forest_grid_search_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 500}\n",
      "RandomForestClassifier(criterion='entropy', max_depth=8, max_features='log2',\n",
      "                       n_estimators=500)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       132\n",
      "           2       0.99      0.99      0.99       138\n",
      "           3       0.98      0.97      0.97       125\n",
      "           4       0.99      0.99      0.99       149\n",
      "\n",
      "    accuracy                           0.99       544\n",
      "   macro avg       0.99      0.99      0.99       544\n",
      "weighted avg       0.99      0.99      0.99       544\n",
      "\n",
      "[[132   0   0   0]\n",
      " [  0 136   2   0]\n",
      " [  0   2 121   2]\n",
      " [  0   0   1 148]]\n",
      "0.9868403379403903\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, grid_predictions))\n",
    "print(confusion_matrix(y_test, grid_predictions))\n",
    "# print f1 score\n",
    "print(f1_score(y_test, grid_predictions, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
