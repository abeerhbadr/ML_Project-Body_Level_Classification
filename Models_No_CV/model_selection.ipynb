{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../'); sys.path.append('../Preprocess/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import time\n",
    "from preprocess2 import *\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "applySmote = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Veg_Consump</th>\n",
       "      <th>Water_Consump</th>\n",
       "      <th>Meal_Count</th>\n",
       "      <th>Phys_Act</th>\n",
       "      <th>Time_E_Dev</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>Fam_Hist_no</th>\n",
       "      <th>Fam_Hist_yes</th>\n",
       "      <th>H_Cal_Burn_no</th>\n",
       "      <th>H_Cal_Burn_yes</th>\n",
       "      <th>Transport_Automobile</th>\n",
       "      <th>Transport_Bike</th>\n",
       "      <th>Transport_Motorbike</th>\n",
       "      <th>Transport_Public_Transportation</th>\n",
       "      <th>Transport_Walking</th>\n",
       "      <th>Body_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.547298</td>\n",
       "      <td>1.722461</td>\n",
       "      <td>51.881263</td>\n",
       "      <td>2.663421</td>\n",
       "      <td>1.041110</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>1.391948</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.799054</td>\n",
       "      <td>1.743702</td>\n",
       "      <td>54.927529</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.847264</td>\n",
       "      <td>3.289260</td>\n",
       "      <td>1.680844</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.823438</td>\n",
       "      <td>1.708406</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.642241</td>\n",
       "      <td>1.099231</td>\n",
       "      <td>3.452590</td>\n",
       "      <td>0.418875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.007177</td>\n",
       "      <td>1.690727</td>\n",
       "      <td>49.895716</td>\n",
       "      <td>1.212908</td>\n",
       "      <td>1.029703</td>\n",
       "      <td>3.207071</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.729250</td>\n",
       "      <td>1.793315</td>\n",
       "      <td>58.195150</td>\n",
       "      <td>2.508835</td>\n",
       "      <td>2.076933</td>\n",
       "      <td>3.435905</td>\n",
       "      <td>2.026668</td>\n",
       "      <td>1.443328</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age    Height     Weight  Veg_Consump  Water_Consump  Meal_Count   \n",
       "0  22.547298  1.722461  51.881263     2.663421       1.041110    3.000000  \\\n",
       "1  19.799054  1.743702  54.927529     2.000000       2.847264    3.289260   \n",
       "2  17.823438  1.708406  50.000000     1.642241       1.099231    3.452590   \n",
       "3  19.007177  1.690727  49.895716     1.212908       1.029703    3.207071   \n",
       "4  19.729250  1.793315  58.195150     2.508835       2.076933    3.435905   \n",
       "\n",
       "   Phys_Act  Time_E_Dev  Gender_Female  Gender_Male  ...  Fam_Hist_no   \n",
       "0  0.794402    1.391948           True        False  ...        False  \\\n",
       "1  1.680844    2.000000          False         True  ...        False   \n",
       "2  0.418875    1.000000           True        False  ...         True   \n",
       "3  2.000000    1.000000           True        False  ...         True   \n",
       "4  2.026668    1.443328          False         True  ...        False   \n",
       "\n",
       "   Fam_Hist_yes  H_Cal_Burn_no  H_Cal_Burn_yes  Transport_Automobile   \n",
       "0          True           True           False                 False  \\\n",
       "1          True           True           False                 False   \n",
       "2         False           True           False                 False   \n",
       "3         False           True           False                 False   \n",
       "4          True           True           False                  True   \n",
       "\n",
       "   Transport_Bike  Transport_Motorbike  Transport_Public_Transportation   \n",
       "0           False                False                             True  \\\n",
       "1           False                False                             True   \n",
       "2           False                False                             True   \n",
       "3           False                False                             True   \n",
       "4           False                False                            False   \n",
       "\n",
       "   Transport_Walking  Body_Level  \n",
       "0              False           0  \n",
       "1              False           0  \n",
       "2              False           0  \n",
       "3              False           0  \n",
       "4              False           0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessor()\n",
    "df_h = preprocessor.preprocess()\n",
    "df_h.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks like SVM Overfits, specially with high C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.9940728196443692\n",
      "train precision:  0.9906629894236427\n",
      "train recall:  0.990515935214211\n",
      "train f1:  0.9905681222113505\n",
      "\n",
      "accuracy:  0.9797297297297297\n",
      "precision:  0.9748976513682396\n",
      "recall:  0.9730866274179983\n",
      "f1:  0.9736505010398941\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "\n",
    "# SVM\n",
    "# svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm = SVC(kernel='linear', C= 100, random_state=0)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# train accuracy, precision, recall, f1\n",
    "print('train accuracy: ', accuracy_score(y_train, svm.predict(X_train)))\n",
    "print('train precision: ', precision_score(y_train, svm.predict(X_train), average='macro'))\n",
    "print('train recall: ', recall_score(y_train, svm.predict(X_train), average='macro'))\n",
    "print('train f1: ', f1_score(y_train, svm.predict(X_train), average='macro'))\n",
    "\n",
    "print()\n",
    "# accuracy, precision, recall, f1\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('f1: ', f1_score(y_test, y_pred, average='macro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.793918918918919\n",
      "precision:  0.6256887046412667\n",
      "recall:  0.616535604149145\n",
      "f1:  0.6130446543166778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akram/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# applySmote = True\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "\n",
    "# linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "# accuracy, precision, recall, f1\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('f1: ', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.9043183742591024\n",
      "train precision:  0.8775490945444013\n",
      "train recall:  0.874273431466085\n",
      "train f1:  0.874120080494378\n",
      "\n",
      "accuracy:  0.8716216216216216\n",
      "precision:  0.8462122372401117\n",
      "recall:  0.8528796958228203\n",
      "f1:  0.8459289610438119\n"
     ]
    }
   ],
   "source": [
    "# logistic regression, we have 4 classes\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "\n",
    "\n",
    "# logistic regression\n",
    "lr = LogisticRegression( solver='lbfgs', multi_class='multinomial', max_iter=5000, random_state=0, penalty='l2')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# train accuracy, precision, recall, f1\n",
    "print('train accuracy: ', accuracy_score(y_train, lr.predict(X_train)))\n",
    "print('train precision: ', precision_score(y_train, lr.predict(X_train), average='macro'))\n",
    "print('train recall: ', recall_score(y_train, lr.predict(X_train), average='macro'))\n",
    "print('train f1: ', f1_score(y_train, lr.predict(X_train), average='macro'))\n",
    "\n",
    "print()\n",
    "# accuracy, precision, recall, f1\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('f1: ', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.7781541066892464\n",
      "train precision:  0.7235967914826364\n",
      "train recall:  0.7257154093407842\n",
      "train f1:  0.7156824112652663\n",
      "\n",
      "accuracy:  0.7195945945945946\n",
      "precision:  0.665854135129511\n",
      "recall:  0.6724395281398934\n",
      "f1:  0.6618753146078727\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "    \n",
    "# SVM\n",
    "svm = SVC(kernel='rbf', C=1.0, random_state=0)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# train accuracy, precision, recall, f1\n",
    "print('train accuracy: ', accuracy_score(y_train, svm.predict(X_train)))\n",
    "print('train precision: ', precision_score(y_train, svm.predict(X_train), average='macro'))\n",
    "print('train recall: ', recall_score(y_train, svm.predict(X_train), average='macro'))\n",
    "print('train f1: ', f1_score(y_train, svm.predict(X_train), average='macro'))\n",
    "\n",
    "print()\n",
    "# accuracy, precision, recall, f1\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('f1: ', f1_score(y_test, y_pred, average='macro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.7281964436917866\n",
      "train precision:  0.7068533943772393\n",
      "train recall:  0.6663080817545772\n",
      "train f1:  0.6799915833855088\n",
      "\n",
      "accuracy:  0.6587837837837838\n",
      "precision:  0.6126143009576293\n",
      "recall:  0.5860350741169049\n",
      "f1:  0.595458936829122\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "    \n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "nb = MultinomialNB()\n",
    "# nb = GaussianNB( )\n",
    "# nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# train accuracy, precision, recall, f1\n",
    "print('train accuracy: ', accuracy_score(y_train, nb.predict(X_train)))\n",
    "print('train precision: ', precision_score(y_train, nb.predict(X_train), average='macro'))\n",
    "print('train recall: ', recall_score(y_train, nb.predict(X_train), average='macro'))\n",
    "print('train f1: ', f1_score(y_train, nb.predict(X_train), average='macro'))\n",
    "\n",
    "print()\n",
    "# accuracy, precision, recall, f1\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('f1: ', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM linear with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:  [150 160 319 552]\n",
      "After SMOTE:  [552 552 552 552]\n",
      "\n",
      "train accuracy:  0.9977355072463768\n",
      "train precision:  0.9977395843657325\n",
      "train recall:  0.9977355072463768\n",
      "train f1:  0.9977355009293448\n",
      "\n",
      "accuracy:  0.9662162162162162\n",
      "precision:  0.9579890308607981\n",
      "recall:  0.9569852554667788\n",
      "f1:  0.9563375292092965\n"
     ]
    }
   ],
   "source": [
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# apply smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# check the number of samples per class\n",
    "print('Before SMOTE: ', np.bincount(y_train))\n",
    "print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "\n",
    "print()\n",
    "\n",
    "# SVM, linear, C=10\n",
    "svm = SVC(kernel='linear', C=100, random_state=0)\n",
    "svm.fit(X_train_smote, y_train_smote)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# train accuracy, precision, recall, f1\n",
    "print('train accuracy: ', accuracy_score(y_train_smote, svm.predict(X_train_smote)))\n",
    "print('train precision: ', precision_score(y_train_smote, svm.predict(X_train_smote), average='macro'))\n",
    "print('train recall: ', recall_score(y_train_smote, svm.predict(X_train_smote), average='macro'))\n",
    "print('train f1: ', f1_score(y_train_smote, svm.predict(X_train_smote), average='macro'))\n",
    "\n",
    "print()\n",
    "# accuracy, precision, recall, f1\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('f1: ', f1_score(y_test, y_pred, average='macro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2449449\ttotal: 105ms\tremaining: 10.4s\n",
      "1:\tlearn: 1.1339118\ttotal: 117ms\tremaining: 5.73s\n",
      "2:\tlearn: 1.0272223\ttotal: 130ms\tremaining: 4.21s\n",
      "3:\tlearn: 0.9358980\ttotal: 140ms\tremaining: 3.37s\n",
      "4:\tlearn: 0.8759126\ttotal: 148ms\tremaining: 2.82s\n",
      "5:\tlearn: 0.8011394\ttotal: 157ms\tremaining: 2.45s\n",
      "6:\tlearn: 0.7337919\ttotal: 163ms\tremaining: 2.16s\n",
      "7:\tlearn: 0.6913820\ttotal: 169ms\tremaining: 1.95s\n",
      "8:\tlearn: 0.6496348\ttotal: 175ms\tremaining: 1.77s\n",
      "9:\tlearn: 0.6096378\ttotal: 180ms\tremaining: 1.62s\n",
      "10:\tlearn: 0.5811812\ttotal: 186ms\tremaining: 1.5s\n",
      "11:\tlearn: 0.5584318\ttotal: 190ms\tremaining: 1.39s\n",
      "12:\tlearn: 0.5282805\ttotal: 193ms\tremaining: 1.29s\n",
      "13:\tlearn: 0.4960504\ttotal: 197ms\tremaining: 1.21s\n",
      "14:\tlearn: 0.4725373\ttotal: 203ms\tremaining: 1.15s\n",
      "15:\tlearn: 0.4550466\ttotal: 207ms\tremaining: 1.09s\n",
      "16:\tlearn: 0.4335506\ttotal: 211ms\tremaining: 1.03s\n",
      "17:\tlearn: 0.4142997\ttotal: 215ms\tremaining: 981ms\n",
      "18:\tlearn: 0.4026071\ttotal: 220ms\tremaining: 939ms\n",
      "19:\tlearn: 0.3910405\ttotal: 224ms\tremaining: 895ms\n",
      "20:\tlearn: 0.3789217\ttotal: 227ms\tremaining: 856ms\n",
      "21:\tlearn: 0.3638092\ttotal: 231ms\tremaining: 821ms\n",
      "22:\tlearn: 0.3522298\ttotal: 236ms\tremaining: 790ms\n",
      "23:\tlearn: 0.3397206\ttotal: 240ms\tremaining: 760ms\n",
      "24:\tlearn: 0.3274104\ttotal: 244ms\tremaining: 731ms\n",
      "25:\tlearn: 0.3169931\ttotal: 248ms\tremaining: 707ms\n",
      "26:\tlearn: 0.3098553\ttotal: 254ms\tremaining: 688ms\n",
      "27:\tlearn: 0.3023102\ttotal: 259ms\tremaining: 666ms\n",
      "28:\tlearn: 0.2904693\ttotal: 263ms\tremaining: 645ms\n",
      "29:\tlearn: 0.2797621\ttotal: 269ms\tremaining: 628ms\n",
      "30:\tlearn: 0.2728243\ttotal: 273ms\tremaining: 608ms\n",
      "31:\tlearn: 0.2644439\ttotal: 277ms\tremaining: 589ms\n",
      "32:\tlearn: 0.2599591\ttotal: 283ms\tremaining: 575ms\n",
      "33:\tlearn: 0.2550743\ttotal: 287ms\tremaining: 558ms\n",
      "34:\tlearn: 0.2442054\ttotal: 292ms\tremaining: 542ms\n",
      "35:\tlearn: 0.2396636\ttotal: 296ms\tremaining: 527ms\n",
      "36:\tlearn: 0.2336088\ttotal: 302ms\tremaining: 514ms\n",
      "37:\tlearn: 0.2276559\ttotal: 307ms\tremaining: 501ms\n",
      "38:\tlearn: 0.2210746\ttotal: 312ms\tremaining: 487ms\n",
      "39:\tlearn: 0.2147578\ttotal: 317ms\tremaining: 475ms\n",
      "40:\tlearn: 0.2109795\ttotal: 322ms\tremaining: 463ms\n",
      "41:\tlearn: 0.2071697\ttotal: 327ms\tremaining: 451ms\n",
      "42:\tlearn: 0.2034533\ttotal: 332ms\tremaining: 441ms\n",
      "43:\tlearn: 0.1988556\ttotal: 337ms\tremaining: 428ms\n",
      "44:\tlearn: 0.1953224\ttotal: 342ms\tremaining: 417ms\n",
      "45:\tlearn: 0.1921840\ttotal: 347ms\tremaining: 407ms\n",
      "46:\tlearn: 0.1903837\ttotal: 352ms\tremaining: 396ms\n",
      "47:\tlearn: 0.1881952\ttotal: 356ms\tremaining: 385ms\n",
      "48:\tlearn: 0.1858394\ttotal: 361ms\tremaining: 376ms\n",
      "49:\tlearn: 0.1815387\ttotal: 368ms\tremaining: 368ms\n",
      "50:\tlearn: 0.1782038\ttotal: 373ms\tremaining: 358ms\n",
      "51:\tlearn: 0.1756864\ttotal: 378ms\tremaining: 349ms\n",
      "52:\tlearn: 0.1730409\ttotal: 386ms\tremaining: 342ms\n",
      "53:\tlearn: 0.1701615\ttotal: 391ms\tremaining: 333ms\n",
      "54:\tlearn: 0.1671707\ttotal: 396ms\tremaining: 324ms\n",
      "55:\tlearn: 0.1651125\ttotal: 401ms\tremaining: 315ms\n",
      "56:\tlearn: 0.1638125\ttotal: 408ms\tremaining: 308ms\n",
      "57:\tlearn: 0.1623258\ttotal: 419ms\tremaining: 304ms\n",
      "58:\tlearn: 0.1571285\ttotal: 427ms\tremaining: 296ms\n",
      "59:\tlearn: 0.1550393\ttotal: 435ms\tremaining: 290ms\n",
      "60:\tlearn: 0.1529023\ttotal: 443ms\tremaining: 283ms\n",
      "61:\tlearn: 0.1510479\ttotal: 450ms\tremaining: 276ms\n",
      "62:\tlearn: 0.1492956\ttotal: 455ms\tremaining: 267ms\n",
      "63:\tlearn: 0.1475948\ttotal: 463ms\tremaining: 260ms\n",
      "64:\tlearn: 0.1443778\ttotal: 468ms\tremaining: 252ms\n",
      "65:\tlearn: 0.1429993\ttotal: 473ms\tremaining: 244ms\n",
      "66:\tlearn: 0.1406637\ttotal: 481ms\tremaining: 237ms\n",
      "67:\tlearn: 0.1401078\ttotal: 487ms\tremaining: 229ms\n",
      "68:\tlearn: 0.1391706\ttotal: 494ms\tremaining: 222ms\n",
      "69:\tlearn: 0.1350551\ttotal: 500ms\tremaining: 214ms\n",
      "70:\tlearn: 0.1328481\ttotal: 504ms\tremaining: 206ms\n",
      "71:\tlearn: 0.1312973\ttotal: 509ms\tremaining: 198ms\n",
      "72:\tlearn: 0.1303278\ttotal: 515ms\tremaining: 190ms\n",
      "73:\tlearn: 0.1273645\ttotal: 520ms\tremaining: 183ms\n",
      "74:\tlearn: 0.1253392\ttotal: 525ms\tremaining: 175ms\n",
      "75:\tlearn: 0.1238713\ttotal: 531ms\tremaining: 168ms\n",
      "76:\tlearn: 0.1227032\ttotal: 535ms\tremaining: 160ms\n",
      "77:\tlearn: 0.1198974\ttotal: 539ms\tremaining: 152ms\n",
      "78:\tlearn: 0.1180760\ttotal: 544ms\tremaining: 145ms\n",
      "79:\tlearn: 0.1170078\ttotal: 548ms\tremaining: 137ms\n",
      "80:\tlearn: 0.1151643\ttotal: 553ms\tremaining: 130ms\n",
      "81:\tlearn: 0.1141461\ttotal: 559ms\tremaining: 123ms\n",
      "82:\tlearn: 0.1114407\ttotal: 564ms\tremaining: 116ms\n",
      "83:\tlearn: 0.1094322\ttotal: 569ms\tremaining: 108ms\n",
      "84:\tlearn: 0.1079179\ttotal: 575ms\tremaining: 101ms\n",
      "85:\tlearn: 0.1070734\ttotal: 580ms\tremaining: 94.4ms\n",
      "86:\tlearn: 0.1058512\ttotal: 584ms\tremaining: 87.3ms\n",
      "87:\tlearn: 0.1044337\ttotal: 589ms\tremaining: 80.3ms\n",
      "88:\tlearn: 0.1035190\ttotal: 594ms\tremaining: 73.4ms\n",
      "89:\tlearn: 0.1026800\ttotal: 599ms\tremaining: 66.5ms\n",
      "90:\tlearn: 0.1018933\ttotal: 604ms\tremaining: 59.7ms\n",
      "91:\tlearn: 0.1011888\ttotal: 609ms\tremaining: 53ms\n",
      "92:\tlearn: 0.0996487\ttotal: 616ms\tremaining: 46.3ms\n",
      "93:\tlearn: 0.0982786\ttotal: 620ms\tremaining: 39.6ms\n",
      "94:\tlearn: 0.0960235\ttotal: 626ms\tremaining: 32.9ms\n",
      "95:\tlearn: 0.0954252\ttotal: 631ms\tremaining: 26.3ms\n",
      "96:\tlearn: 0.0946468\ttotal: 635ms\tremaining: 19.7ms\n",
      "97:\tlearn: 0.0930354\ttotal: 642ms\tremaining: 13.1ms\n",
      "98:\tlearn: 0.0924064\ttotal: 646ms\tremaining: 6.52ms\n",
      "99:\tlearn: 0.0902658\ttotal: 650ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f399a5affa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create the CatBoost model\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.9966130397967824\n",
      "train precision:  0.9972114718358656\n",
      "train recall:  0.9945288009404388\n",
      "train f1:  0.6799915833855088\n",
      "\n",
      "accuracy:  0.9662162162162162\n",
      "precision:  0.9579890308607981\n",
      "recall:  0.9569852554667788\n",
      "f1:  0.9563375292092965\n"
     ]
    }
   ],
   "source": [
    "# train accuracy, precision, recall, f1\n",
    "print('train accuracy: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('train precision: ', precision_score(y_train, model.predict(X_train), average='macro'))\n",
    "print('train recall: ', recall_score(y_train, model.predict(X_train), average='macro'))\n",
    "print('train f1: ', f1_score(y_train, nb.predict(X_train), average='macro'))\n",
    "\n",
    "print()\n",
    "# accuracy, precision, recall, f1\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('f1: ', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "---------------------------\n",
      "31\n",
      "\n",
      "predictions are : \n",
      " [[2]\n",
      " [2]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with sample data\n",
    "new_data_dict = {\n",
    "    'Age': [32, 45, 21],\n",
    "    'Height': [1.65, 1.75, 1.68],\n",
    "    'Weight': [72, 89, 55],\n",
    "    'Veg_Consump': [3, 2, 4],\n",
    "    'Water_Consump': [4, 3, 2],\n",
    "    'Meal_Count': [3, 4, 2],\n",
    "    'Phys_Act': [2, 3, 4],\n",
    "    'Time_E_Dev': [3, 2, 1],\n",
    "    'Gender_Female': [0, 1, 0],\n",
    "    'Gender_Male': [1, 0, 1],\n",
    "    'H_Cal_Consump_no': [1, 0, 0],\n",
    "    'H_Cal_Consump_yes': [0, 1, 1],\n",
    "    'Alcohol_Consump_Always': [0, 0, 1],\n",
    "    'Alcohol_Consump_Frequently': [1, 0, 0],\n",
    "    'Alcohol_Consump_Sometimes': [0, 1, 0],\n",
    "    'Alcohol_Consump_no': [0, 0, 0],\n",
    "    'Smoking_no': [1, 1, 0],\n",
    "    'Smoking_yes': [0, 0, 1],\n",
    "    'Food_Between_Meals_Always': [0, 1, 0],\n",
    "    'Food_Between_Meals_Frequently': [0, 0, 1],\n",
    "    'Food_Between_Meals_Sometimes': [1, 0, 0],\n",
    "    'Food_Between_Meals_no': [0, 0, 0],\n",
    "    'Fam_Hist_no': [1, 0, 1],\n",
    "    'Fam_Hist_yes': [0, 1, 0],\n",
    "    'H_Cal_Burn_no': [1, 0, 0],\n",
    "    'H_Cal_Burn_yes': [0, 1, 1],\n",
    "    'Transport_Automobile': [1, 0, 0],\n",
    "    'Transport_Bike': [0, 1, 0],\n",
    "    'Transport_Motorbike': [0, 0, 1],\n",
    "    'Transport_Public_Transportation': [0, 0, 0],\n",
    "    'Transport_Walking': [0, 0, 0]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a Pandas DataFrame\n",
    "new_data = pd.DataFrame(new_data_dict)\n",
    "\n",
    "print(len(df_h.columns))\n",
    "print(\"---------------------------\")\n",
    "print(len(new_data.columns))\n",
    "print(\"\")\n",
    "\n",
    "# Make prediction using the model\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Print the predicted class labels\n",
    "print(\"predictions are : \\n\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
