{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../'); sys.path.append('../Preprocess/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# use sklearn metrics, single function\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time\n",
    "from Preprocess.preprocess2 import *\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "applySmote = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Veg_Consump</th>\n",
       "      <th>Water_Consump</th>\n",
       "      <th>Meal_Count</th>\n",
       "      <th>Phys_Act</th>\n",
       "      <th>Time_E_Dev</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>Fam_Hist_no</th>\n",
       "      <th>Fam_Hist_yes</th>\n",
       "      <th>H_Cal_Burn_no</th>\n",
       "      <th>H_Cal_Burn_yes</th>\n",
       "      <th>Transport_Automobile</th>\n",
       "      <th>Transport_Bike</th>\n",
       "      <th>Transport_Motorbike</th>\n",
       "      <th>Transport_Public_Transportation</th>\n",
       "      <th>Transport_Walking</th>\n",
       "      <th>Body_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.547298</td>\n",
       "      <td>1.722461</td>\n",
       "      <td>51.881263</td>\n",
       "      <td>2.663421</td>\n",
       "      <td>1.041110</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>1.391948</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.799054</td>\n",
       "      <td>1.743702</td>\n",
       "      <td>54.927529</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.847264</td>\n",
       "      <td>3.289260</td>\n",
       "      <td>1.680844</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.823438</td>\n",
       "      <td>1.708406</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.642241</td>\n",
       "      <td>1.099231</td>\n",
       "      <td>3.452590</td>\n",
       "      <td>0.418875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.007177</td>\n",
       "      <td>1.690727</td>\n",
       "      <td>49.895716</td>\n",
       "      <td>1.212908</td>\n",
       "      <td>1.029703</td>\n",
       "      <td>3.207071</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.729250</td>\n",
       "      <td>1.793315</td>\n",
       "      <td>58.195150</td>\n",
       "      <td>2.508835</td>\n",
       "      <td>2.076933</td>\n",
       "      <td>3.435905</td>\n",
       "      <td>2.026668</td>\n",
       "      <td>1.443328</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age    Height     Weight  Veg_Consump  Water_Consump  Meal_Count  \\\n",
       "0  22.547298  1.722461  51.881263     2.663421       1.041110    3.000000   \n",
       "1  19.799054  1.743702  54.927529     2.000000       2.847264    3.289260   \n",
       "2  17.823438  1.708406  50.000000     1.642241       1.099231    3.452590   \n",
       "3  19.007177  1.690727  49.895716     1.212908       1.029703    3.207071   \n",
       "4  19.729250  1.793315  58.195150     2.508835       2.076933    3.435905   \n",
       "\n",
       "   Phys_Act  Time_E_Dev  Gender_Female  Gender_Male  ...  Fam_Hist_no  \\\n",
       "0  0.794402    1.391948              1            0  ...            0   \n",
       "1  1.680844    2.000000              0            1  ...            0   \n",
       "2  0.418875    1.000000              1            0  ...            1   \n",
       "3  2.000000    1.000000              1            0  ...            1   \n",
       "4  2.026668    1.443328              0            1  ...            0   \n",
       "\n",
       "   Fam_Hist_yes  H_Cal_Burn_no  H_Cal_Burn_yes  Transport_Automobile  \\\n",
       "0             1              1               0                     0   \n",
       "1             1              1               0                     0   \n",
       "2             0              1               0                     0   \n",
       "3             0              1               0                     0   \n",
       "4             1              1               0                     1   \n",
       "\n",
       "   Transport_Bike  Transport_Motorbike  Transport_Public_Transportation  \\\n",
       "0               0                    0                                1   \n",
       "1               0                    0                                1   \n",
       "2               0                    0                                1   \n",
       "3               0                    0                                1   \n",
       "4               0                    0                                0   \n",
       "\n",
       "   Transport_Walking  Body_Level  \n",
       "0                  0           0  \n",
       "1                  0           0  \n",
       "2                  0           0  \n",
       "3                  0           0  \n",
       "4                  0           0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessor()\n",
    "df_h = preprocessor.preprocess()\n",
    "df_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>H_Cal_Consump</th>\n",
       "      <th>Veg_Consump</th>\n",
       "      <th>Water_Consump</th>\n",
       "      <th>Alcohol_Consump</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Meal_Count</th>\n",
       "      <th>Food_Between_Meals</th>\n",
       "      <th>Fam_Hist</th>\n",
       "      <th>H_Cal_Burn</th>\n",
       "      <th>Phys_Act</th>\n",
       "      <th>Time_E_Dev</th>\n",
       "      <th>Transport</th>\n",
       "      <th>Body_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.547298</td>\n",
       "      <td>1.722461</td>\n",
       "      <td>51.881263</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.663421</td>\n",
       "      <td>1.041110</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>1.391948</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>19.799054</td>\n",
       "      <td>1.743702</td>\n",
       "      <td>54.927529</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.847264</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.289260</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.680844</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>17.823438</td>\n",
       "      <td>1.708406</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.642241</td>\n",
       "      <td>1.099231</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.452590</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0.418875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>19.007177</td>\n",
       "      <td>1.690727</td>\n",
       "      <td>49.895716</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.212908</td>\n",
       "      <td>1.029703</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.207071</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>19.729250</td>\n",
       "      <td>1.793315</td>\n",
       "      <td>58.195150</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.508835</td>\n",
       "      <td>2.076933</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.435905</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.026668</td>\n",
       "      <td>1.443328</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender        Age    Height     Weight H_Cal_Consump  Veg_Consump  \\\n",
       "0  Female  22.547298  1.722461  51.881263           yes     2.663421   \n",
       "1    Male  19.799054  1.743702  54.927529           yes     2.000000   \n",
       "2  Female  17.823438  1.708406  50.000000           yes     1.642241   \n",
       "3  Female  19.007177  1.690727  49.895716           yes     1.212908   \n",
       "4    Male  19.729250  1.793315  58.195150           yes     2.508835   \n",
       "\n",
       "   Water_Consump Alcohol_Consump Smoking  Meal_Count Food_Between_Meals  \\\n",
       "0       1.041110              no      no    3.000000         Frequently   \n",
       "1       2.847264       Sometimes      no    3.289260          Sometimes   \n",
       "2       1.099231       Sometimes      no    3.452590          Sometimes   \n",
       "3       1.029703       Sometimes      no    3.207071          Sometimes   \n",
       "4       2.076933              no      no    3.435905          Sometimes   \n",
       "\n",
       "  Fam_Hist H_Cal_Burn  Phys_Act  Time_E_Dev              Transport  \\\n",
       "0      yes         no  0.794402    1.391948  Public_Transportation   \n",
       "1      yes         no  1.680844    2.000000  Public_Transportation   \n",
       "2       no         no  0.418875    1.000000  Public_Transportation   \n",
       "3       no         no  2.000000    1.000000  Public_Transportation   \n",
       "4      yes         no  2.026668    1.443328             Automobile   \n",
       "\n",
       "     Body_Level  \n",
       "0  Body Level 1  \n",
       "1  Body Level 1  \n",
       "2  Body Level 1  \n",
       "3  Body Level 1  \n",
       "4  Body Level 1  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h = pd.read_csv('../dataset/body_level_classification_train.csv')\n",
    "df_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>H_Cal_Consump</th>\n",
       "      <th>Veg_Consump</th>\n",
       "      <th>Water_Consump</th>\n",
       "      <th>Alcohol_Consump</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Meal_Count</th>\n",
       "      <th>Food_Between_Meals</th>\n",
       "      <th>Fam_Hist</th>\n",
       "      <th>H_Cal_Burn</th>\n",
       "      <th>Phys_Act</th>\n",
       "      <th>Time_E_Dev</th>\n",
       "      <th>Transport</th>\n",
       "      <th>Body_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.547298</td>\n",
       "      <td>1.722461</td>\n",
       "      <td>51.881263</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.663421</td>\n",
       "      <td>1.041110</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>1.391948</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>19.799054</td>\n",
       "      <td>1.743702</td>\n",
       "      <td>54.927529</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.847264</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.289260</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.680844</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>17.823438</td>\n",
       "      <td>1.708406</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.642241</td>\n",
       "      <td>1.099231</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.452590</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0.418875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>19.007177</td>\n",
       "      <td>1.690727</td>\n",
       "      <td>49.895716</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.212908</td>\n",
       "      <td>1.029703</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.207071</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>19.729250</td>\n",
       "      <td>1.793315</td>\n",
       "      <td>58.195150</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.508835</td>\n",
       "      <td>2.076933</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.435905</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.026668</td>\n",
       "      <td>1.443328</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Body Level 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender        Age    Height     Weight H_Cal_Consump  Veg_Consump  \\\n",
       "0  Female  22.547298  1.722461  51.881263           yes     2.663421   \n",
       "1    Male  19.799054  1.743702  54.927529           yes     2.000000   \n",
       "2  Female  17.823438  1.708406  50.000000           yes     1.642241   \n",
       "3  Female  19.007177  1.690727  49.895716           yes     1.212908   \n",
       "4    Male  19.729250  1.793315  58.195150           yes     2.508835   \n",
       "\n",
       "   Water_Consump Alcohol_Consump Smoking  Meal_Count Food_Between_Meals  \\\n",
       "0       1.041110              no      no    3.000000         Frequently   \n",
       "1       2.847264       Sometimes      no    3.289260          Sometimes   \n",
       "2       1.099231       Sometimes      no    3.452590          Sometimes   \n",
       "3       1.029703       Sometimes      no    3.207071          Sometimes   \n",
       "4       2.076933              no      no    3.435905          Sometimes   \n",
       "\n",
       "  Fam_Hist H_Cal_Burn  Phys_Act  Time_E_Dev              Transport  \\\n",
       "0      yes         no  0.794402    1.391948  Public_Transportation   \n",
       "1      yes         no  1.680844    2.000000  Public_Transportation   \n",
       "2       no         no  0.418875    1.000000  Public_Transportation   \n",
       "3       no         no  2.000000    1.000000  Public_Transportation   \n",
       "4      yes         no  2.026668    1.443328             Automobile   \n",
       "\n",
       "     Body_Level  \n",
       "0  Body Level 1  \n",
       "1  Body Level 1  \n",
       "2  Body Level 1  \n",
       "3  Body Level 1  \n",
       "4  Body Level 1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics for XGBoost:\n",
      "[[159   0   0   0]\n",
      " [  0 156   0   0]\n",
      " [  0   0 324   0]\n",
      " [  0   0   0 542]]\n",
      "\n",
      "Testing Metrics for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9394    1.0000    0.9688        31\n",
      "           1     0.9762    0.9111    0.9425        45\n",
      "           2     0.9750    0.9512    0.9630        82\n",
      "           3     0.9787    1.0000    0.9892       138\n",
      "\n",
      "    accuracy                         0.9730       296\n",
      "   macro avg     0.9673    0.9656    0.9659       296\n",
      "weighted avg     0.9732    0.9730    0.9727       296\n",
      "\n",
      "[[ 31   0   0   0]\n",
      " [  2  41   2   0]\n",
      " [  0   1  78   3]\n",
      " [  0   0   0 138]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "X = df_h.iloc[:, :-1]\n",
    "y = df_h.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "                            booster='gbtree',\n",
    "                            learning_rate=0.3,\n",
    "                            max_depth=3,\n",
    "                            objective=\"multi:softprob\",\n",
    "                            random_state=42,\n",
    "                            num_class=4,\n",
    "                            # eval_metric=\"auc\",\n",
    "                            eval_metric=\"mlogloss\",\n",
    "                            )\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = xgb_model.predict(X_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print('Training Metrics for XGBoost:')\n",
    "# print(classification_report(y_train, y_pred_train, digits=4))\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "# print(classification_report(y_train, y_pred_train, digits=4).split('\\n')[-2])\n",
    "# print(classification_report(y_test, y_pred, digits=4).split('\\n')[-2])\n",
    "\n",
    "print('\\nTesting Metrics for XGBoost:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted avg     1.0000    1.0000    1.0000      1181\n",
      "weighted avg     0.9769    0.9764    0.9761       296\n",
      "\n",
      "Testing Metrics for LightGBM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9394    1.0000    0.9688        31\n",
      "           1     1.0000    0.9111    0.9535        45\n",
      "           2     0.9753    0.9634    0.9693        82\n",
      "           3     0.9787    1.0000    0.9892       138\n",
      "\n",
      "    accuracy                         0.9764       296\n",
      "   macro avg     0.9734    0.9686    0.9702       296\n",
      "weighted avg     0.9769    0.9764    0.9761       296\n",
      "\n",
      "[[ 31   0   0   0]\n",
      " [  2  41   2   0]\n",
      " [  0   0  79   3]\n",
      " [  0   0   0 138]]\n",
      "[[1.         0.         0.         0.        ]\n",
      " [0.04444444 0.91111111 0.04444444 0.        ]\n",
      " [0.         0.         0.96341463 0.03658537]\n",
      " [0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# lightgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "    \n",
    "lgb_model = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    class_weight=None,\n",
    "    # importance_type='split',\n",
    "    learning_rate=0.2,\n",
    "    # max_depth=-1,\n",
    "    # min_child_samples=20,\n",
    "    # min_child_weight=0.001,\n",
    "    # min_split_gain=0.0,\n",
    "    n_estimators=1000,\n",
    "    # num_leaves=31,\n",
    "    objective='multiclass',\n",
    "    # reg_alpha=0.0,\n",
    "    # reg_lambda=0.,\n",
    "    # verbose=-10\n",
    ")\n",
    "\n",
    "# lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = lgb_model.predict(X_train)\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# print('Training Metrics for LightGBM:')\n",
    "# print(classification_report(y_train, y_pred_train, digits=4))\n",
    "# print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "print(classification_report(y_train, y_pred_train, digits=4).split('\\n')[-2])\n",
    "print(classification_report(y_test, y_pred, digits=4).split('\\n')[-2])\n",
    "\n",
    "print('\\nTesting Metrics for LightGBM:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks like SVM Overfits, specially with high C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9803    0.9933    0.9868       150\n",
      "           1     0.9873    0.9750    0.9811       160\n",
      "           2     0.9969    0.9937    0.9953       319\n",
      "           3     0.9982    1.0000    0.9991       552\n",
      "\n",
      "    accuracy                         0.9941      1181\n",
      "   macro avg     0.9907    0.9905    0.9906      1181\n",
      "weighted avg     0.9941    0.9941    0.9941      1181\n",
      "\n",
      "\n",
      "Testing Metrics for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    1.0000    0.9756        40\n",
      "           1     0.9744    0.9268    0.9500        41\n",
      "           2     0.9882    0.9655    0.9767        87\n",
      "           3     0.9846    1.0000    0.9922       128\n",
      "\n",
      "    accuracy                         0.9797       296\n",
      "   macro avg     0.9749    0.9731    0.9737       296\n",
      "weighted avg     0.9799    0.9797    0.9796       296\n",
      "\n",
      "[[ 40   0   0   0]\n",
      " [  2  38   1   0]\n",
      " [  0   1  84   2]\n",
      " [  0   0   0 128]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "\n",
    "# SVM\n",
    "# svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm = SVC(kernel='linear', C= 100, random_state=0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print('Training Metrics for SVM:')\n",
    "print(classification_report(y_train, y_pred_train, digits=4))\n",
    "# print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "print('\\nTesting Metrics for SVM:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics for Linear Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     0.0000    0.0000    0.0000         0\n",
      "         0.0     0.9182    0.6733    0.7769       150\n",
      "         1.0     0.6029    0.7875    0.6829       160\n",
      "         2.0     0.7514    0.8715    0.8070       319\n",
      "         3.0     0.9873    0.8442    0.9102       552\n",
      "         4.0     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.8222      1181\n",
      "   macro avg     0.5433    0.5294    0.5295      1181\n",
      "weighted avg     0.8627    0.8222    0.8346      1181\n",
      "\n",
      "\n",
      "Testing Metrics for Linear Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8710    0.6750    0.7606        40\n",
      "         1.0     0.5536    0.7561    0.6392        41\n",
      "         2.0     0.7228    0.8391    0.7766        87\n",
      "         3.0     0.9811    0.8125    0.8889       128\n",
      "         4.0     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.7939       296\n",
      "   macro avg     0.6257    0.6165    0.6130       296\n",
      "weighted avg     0.8311    0.7939    0.8040       296\n",
      "\n",
      "[[ 27  13   0   0   0]\n",
      " [  4  31   6   0   0]\n",
      " [  0  12  73   2   0]\n",
      " [  0   0  22 104   2]\n",
      " [  0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# applySmote = True\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "\n",
    "# linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = np.round(lr.predict(X_train))\n",
    "y_pred = np.round(lr.predict(X_test))\n",
    "\n",
    "print('Training Metrics for Linear Regression:')\n",
    "print(classification_report(y_train, y_pred_train, digits=4))\n",
    "# print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "print('\\nTesting Metrics for Linear Regression:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics for Logistic Reg:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8659    0.9467    0.9045       150\n",
      "           1     0.8222    0.6937    0.7525       160\n",
      "           2     0.8529    0.8903    0.8712       319\n",
      "           3     0.9654    0.9601    0.9628       552\n",
      "\n",
      "    accuracy                         0.9035      1181\n",
      "   macro avg     0.8766    0.8727    0.8727      1181\n",
      "weighted avg     0.9030    0.9035    0.9021      1181\n",
      "\n",
      "\n",
      "Testing Metrics for Logistic Reg:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7959    0.9750    0.8764        40\n",
      "           1     0.8000    0.6829    0.7368        41\n",
      "           2     0.8659    0.8161    0.8402        87\n",
      "           3     0.9231    0.9375    0.9302       128\n",
      "\n",
      "    accuracy                         0.8716       296\n",
      "   macro avg     0.8462    0.8529    0.8459       296\n",
      "weighted avg     0.8720    0.8716    0.8697       296\n",
      "\n",
      "[[ 39   1   0   0]\n",
      " [ 10  28   3   0]\n",
      " [  0   6  71  10]\n",
      " [  0   0   8 120]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression, we have 4 classes\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "\n",
    "\n",
    "# logistic regression\n",
    "lr = LogisticRegression( solver='lbfgs', multi_class='multinomial', max_iter=5000, random_state=0, penalty='l2')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Training Metrics for Logistic Reg:')\n",
    "print(classification_report(y_train, y_pred_train, digits=4))\n",
    "# print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "print('\\nTesting Metrics for Logistic Reg:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics for SVM with RBF Kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7267    0.8333    0.7764       150\n",
      "           1     0.5636    0.3875    0.4593       160\n",
      "           2     0.6513    0.8433    0.7350       319\n",
      "           3     0.9527    0.8388    0.8921       552\n",
      "\n",
      "    accuracy                         0.7782      1181\n",
      "   macro avg     0.7236    0.7257    0.7157      1181\n",
      "weighted avg     0.7899    0.7782    0.7763      1181\n",
      "\n",
      "\n",
      "Testing Metrics for SVM with RBF Kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6522    0.7500    0.6977        40\n",
      "           1     0.4412    0.3659    0.4000        41\n",
      "           2     0.6283    0.8161    0.7100        87\n",
      "           3     0.9417    0.7578    0.8398       128\n",
      "\n",
      "    accuracy                         0.7196       296\n",
      "   macro avg     0.6659    0.6724    0.6619       296\n",
      "weighted avg     0.7412    0.7196    0.7215       296\n",
      "\n",
      "[[30 10  0  0]\n",
      " [15 15 11  0]\n",
      " [ 1  9 71  6]\n",
      " [ 0  0 31 97]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "    \n",
    "# SVM\n",
    "svm = SVC(kernel='rbf', C=1.0, random_state=0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print('Training Metrics for SVM with RBF Kernel:')\n",
    "print(classification_report(y_train, y_pred_train, digits=4))\n",
    "# print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "print('\\nTesting Metrics for SVM with RBF Kernel:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7415    0.7267    0.7340       150\n",
      "           1     0.6952    0.4562    0.5509       160\n",
      "           2     0.5697    0.6019    0.5854       319\n",
      "           3     0.8209    0.8804    0.8497       552\n",
      "\n",
      "    accuracy                         0.7282      1181\n",
      "   macro avg     0.7069    0.6663    0.6800      1181\n",
      "weighted avg     0.7260    0.7282    0.7231      1181\n",
      "\n",
      "\n",
      "Testing Metrics for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6216    0.5750    0.5974        40\n",
      "           1     0.5172    0.3659    0.4286        41\n",
      "           2     0.5217    0.5517    0.5363        87\n",
      "           3     0.7899    0.8516    0.8195       128\n",
      "\n",
      "    accuracy                         0.6588       296\n",
      "   macro avg     0.6126    0.5860    0.5955       296\n",
      "weighted avg     0.6506    0.6588    0.6521       296\n",
      "\n",
      "[[ 23   2  15   0]\n",
      " [ 14  15  11   1]\n",
      " [  0  11  48  28]\n",
      " [  0   1  18 109]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "if applySmote:\n",
    "    print('Before SMOTE: ', np.bincount(y_train))\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    # check the number of samples per class\n",
    "    print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "    print()\n",
    "    X_train = X_train_smote\n",
    "    y_train = y_train_smote\n",
    "    \n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "nb = MultinomialNB()\n",
    "# nb = GaussianNB( )\n",
    "# nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "y_pred_train = nb.predict(X_train)\n",
    "\n",
    "print('Training Metrics for Naive Bayes:')\n",
    "print(classification_report(y_train, y_pred_train, digits=4))\n",
    "# print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "print('\\nTesting Metrics for Naive Bayes:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM linear with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:  [150 160 319 552]\n",
      "After SMOTE:  [552 552 552 552]\n",
      "\n",
      "Training Metrics for SVM linear with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9934    1.0000    0.9967       150\n",
      "           1     0.9876    0.9938    0.9907       160\n",
      "           2     0.9969    0.9937    0.9953       319\n",
      "           3     1.0000    0.9982    0.9991       552\n",
      "\n",
      "    accuracy                         0.9966      1181\n",
      "   macro avg     0.9945    0.9964    0.9954      1181\n",
      "weighted avg     0.9966    0.9966    0.9966      1181\n",
      "\n",
      "\n",
      "Testing Metrics for SVM linear with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    1.0000    0.9524        40\n",
      "           1     0.9730    0.8780    0.9231        41\n",
      "           2     0.9655    0.9655    0.9655        87\n",
      "           3     0.9844    0.9844    0.9844       128\n",
      "\n",
      "    accuracy                         0.9662       296\n",
      "   macro avg     0.9580    0.9570    0.9563       296\n",
      "weighted avg     0.9671    0.9662    0.9660       296\n",
      "\n",
      "[[ 40   0   0   0]\n",
      " [  4  36   1   0]\n",
      " [  0   1  84   2]\n",
      " [  0   0   2 126]]\n"
     ]
    }
   ],
   "source": [
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# apply smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# check the number of samples per class\n",
    "print('Before SMOTE: ', np.bincount(y_train))\n",
    "print('After SMOTE: ', np.bincount(y_train_smote))\n",
    "\n",
    "print()\n",
    "\n",
    "# SVM, linear, C=10\n",
    "svm = SVC(kernel='linear', C=100, random_state=0)\n",
    "svm.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "y_pred_train = svm.predict(X_train)\n",
    "\n",
    "print('Training Metrics for SVM linear with SMOTE:')\n",
    "print(classification_report(y_train, y_pred_train, digits=4))\n",
    "# print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "print('\\nTesting Metrics for SVM linear with SMOTE:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics for Catboost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       150\n",
      "           1     1.0000    0.9812    0.9905       160\n",
      "           2     0.9907    0.9969    0.9938       319\n",
      "           3     0.9982    1.0000    0.9991       552\n",
      "\n",
      "    accuracy                         0.9966      1181\n",
      "   macro avg     0.9972    0.9945    0.9958      1181\n",
      "weighted avg     0.9966    0.9966    0.9966      1181\n",
      "\n",
      "\n",
      "Testing Metrics for Catboost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9750    0.9750    0.9750        40\n",
      "           1     0.9474    0.8780    0.9114        41\n",
      "           2     0.9419    0.9310    0.9364        87\n",
      "           3     0.9621    0.9922    0.9769       128\n",
      "\n",
      "    accuracy                         0.9561       296\n",
      "   macro avg     0.9566    0.9441    0.9499       296\n",
      "weighted avg     0.9559    0.9561    0.9557       296\n",
      "\n",
      "[[ 39   1   0   0]\n",
      " [  1  36   4   0]\n",
      " [  0   1  81   5]\n",
      " [  0   0   1 127]]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X = df_h.iloc[:, :-1].values\n",
    "y = df_h.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create the CatBoost model\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Training Metrics for Catboost:')\n",
    "print(classification_report(y_train, y_pred_train, digits=4))\n",
    "# print(confusion_matrix(y_train, y_pred_train))\n",
    "# print(confusion_matrix(y_train, y_pred_train, normalize='true'))\n",
    "\n",
    "print('\\nTesting Metrics for Catboost:')\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# print(confusion_matrix(y_test, y_pred, normalize='true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "---------------------------\n",
      "31\n",
      "\n",
      "predictions are : \n",
      " [[2]\n",
      " [2]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with sample data\n",
    "new_data_dict = {\n",
    "    'Age': [32, 45, 21],\n",
    "    'Height': [1.65, 1.75, 1.68],\n",
    "    'Weight': [72, 89, 55],\n",
    "    'Veg_Consump': [3, 2, 4],\n",
    "    'Water_Consump': [4, 3, 2],\n",
    "    'Meal_Count': [3, 4, 2],\n",
    "    'Phys_Act': [2, 3, 4],\n",
    "    'Time_E_Dev': [3, 2, 1],\n",
    "    'Gender_Female': [0, 1, 0],\n",
    "    'Gender_Male': [1, 0, 1],\n",
    "    'H_Cal_Consump_no': [1, 0, 0],\n",
    "    'H_Cal_Consump_yes': [0, 1, 1],\n",
    "    'Alcohol_Consump_Always': [0, 0, 1],\n",
    "    'Alcohol_Consump_Frequently': [1, 0, 0],\n",
    "    'Alcohol_Consump_Sometimes': [0, 1, 0],\n",
    "    'Alcohol_Consump_no': [0, 0, 0],\n",
    "    'Smoking_no': [1, 1, 0],\n",
    "    'Smoking_yes': [0, 0, 1],\n",
    "    'Food_Between_Meals_Always': [0, 1, 0],\n",
    "    'Food_Between_Meals_Frequently': [0, 0, 1],\n",
    "    'Food_Between_Meals_Sometimes': [1, 0, 0],\n",
    "    'Food_Between_Meals_no': [0, 0, 0],\n",
    "    'Fam_Hist_no': [1, 0, 1],\n",
    "    'Fam_Hist_yes': [0, 1, 0],\n",
    "    'H_Cal_Burn_no': [1, 0, 0],\n",
    "    'H_Cal_Burn_yes': [0, 1, 1],\n",
    "    'Transport_Automobile': [1, 0, 0],\n",
    "    'Transport_Bike': [0, 1, 0],\n",
    "    'Transport_Motorbike': [0, 0, 1],\n",
    "    'Transport_Public_Transportation': [0, 0, 0],\n",
    "    'Transport_Walking': [0, 0, 0]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a Pandas DataFrame\n",
    "new_data = pd.DataFrame(new_data_dict)\n",
    "\n",
    "print(len(df_h.columns))\n",
    "print(\"---------------------------\")\n",
    "print(len(new_data.columns))\n",
    "print(\"\")\n",
    "\n",
    "# Make prediction using the model\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Print the predicted class labels\n",
    "print(\"predictions are : \\n\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
